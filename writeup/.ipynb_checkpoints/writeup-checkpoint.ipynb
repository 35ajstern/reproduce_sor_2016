{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer review of \n",
    "## Pitt and Hill. SOR 2016\n",
    "\n",
    "[Your author names here]\n",
    "\n",
    "\n",
    "### 1     Summary \n",
    "Pitt and Hill have presented a paper that scrutinizes count data recorded by an individual referred to as \"research teaching specialist\" or \"RTS\" by applying three statistical tests to the RTS data. The authors soundly reject every test of whether certain patterns in the RTS's recorded data occured by chance. Significance of these tests is compared to significance calculated from agglomerated count data recorded by other investigators in RTS's lab and also data from three outside labs, whose data were generated by following \"the same or similar protocols\" as the RTS's lab. No test of either comparison group showed significance.\n",
    "\n",
    "We were able to reproduce most/all the authors' results, and are strongly convinced by these tests that the RTS did alter data. However, we have concerns about statistical assumptions and limitations of the authors' methodology which are not addressed in the paper. Particularly, hope to dissuade readers from extending the authors's methods to *de novo* searches for fraud.\n",
    "\n",
    "### 2     Reproduction\n",
    "We attempted to reproduce the main results (i.e., hypothesis tests) presented in this paper. We roughly organized our reproduction according to the paper's structure. Results of the reproduction are found in the \"reproduce\" folder, compiled as both PDFs and Jupyter notebooks. We were able to reproduce most of the authors' results, with a couple minor discrepancies that could be the result of unspecified filtering (e.g., discounting values under 10 in the equal digit analysis).\n",
    "\n",
    "### 3     Study design\n",
    "\n",
    "A central contribution of this paper are its presentation of novel mid-ratio/mean-containing tests for count data. More precisely, their method assumes that said count data within a triple is $X_i \\sim $ iid Pois$(\\lambda)$ for $i \\in \\{1,2,3\\}$. Does this realistically model the growth/decay of a cell colony? The fate of a cells in a colony is likely dependent on the fates its neighbors; this relationship is not captured in the Poisson model. We find the Poisson assumption unrealistic, and the authors do not engage in a discussion of their tests' behavior when this assumption breaks down. We propose that the authors prove empirically that the triples appear to follow a Poisson distribution, or they try a non-parametric test. \n",
    "\n",
    "While the authors propose a plausible mechanism for how their novel mid-ratio/mean-containing tests might detect fraud, they neglect to mention whether their pursuit of this test came only after they \"peeked\" at the data. Designing a statistical test conscious of the data that is to be tested can often lead to inflated p-values. Also, the authors neglect to mention how many alternative hypothesis tests were considered before the ones that they publish; our concern here is that the authors may merely be publishing a hypothesis test that happened to reject the null among a slew of others that did not. A more convincing method would involve partitioning the data into observed and unobserved data. The observed data can guide the design of tests, but only the unobserved validation set would be used to find significance. \n",
    "\n",
    "Hypothesis test II is based on calculating an exact probability rather than the rough bound used in I. The authors' choice to present both, especially given that the cruder test yields high significance, is confusing. However, we do see some unique value in the cruder test; because $\\hat \\lambda_{ML}$ is an extremely crude estimate for triples, test I seems to be conservative in the chance case of triples that are far from their expectation--say, (100,102,104) when the true $\\lambda = 70$. Conversely, we see this as an issue not addressed in hypothesis test II, where the sample mean with $n=3$ is used to stratify the triples by their \"true\" $\\lambda$. We would encourage the authors to explore via simulations how variance in the sample mean would affect p-value calculation.\n",
    "\n",
    "In the second step, though it is reasonable to use ML estimator as the $\\lambda$ in midprob table, the small sample size (always equal 3) cannot guarantee the asymptotic distribution of the sample mean as a convincing choice. We need sample size to be large enough for MLE estimators to approximate the normal distribution. Nevertheless, with the settings of the author, that all triplets are independent but not identical, this requirement can not be matched. If we accumulate such approximation errors over hundreds of multiplication, the p-value shouldn’t be trusted despite its ‘accuracy’.\n",
    "\n",
    "Thirdly, the success times in RTS’s Poisson binomial is much larger than other investigators (690 v.s. 109). This might also be the reason why multiplication of many binomials leads to smaller p-values in RTS’s experiments. (But I’m not clear how to address this mathematically and rigorously).\n",
    "\n",
    "Hypothesis 3 use the Lindeberg-Feller Central Limit Theorem to approximate the distribution of occurrences of mean containing triples. The p-value of the test would be quite precise given that (1) the distribution of mean containing events for different triples are independently distributed (2) the Poisson distribution assumption is correct (3) the estimations of the Poisson distribution parameter $\\lambda$ give us exact the true value of $\\lambda$ (4) the mean containing probability associated with given Poisson $\\lambda$ is properly calculated. \n",
    "\n",
    "However, the hypothesis test is questionable in that:the Poisson distribution assumption remains unverified, and the authors use the mean of each triple--a highly unstable estimate--as a parameter estimate. Although this estimation is unbiased, the MSE (variance) would be large: $MSE(\\hat\\lambda) = \\text{Var}(\\hat\\lambda) = 1/9(\\sum ^3_{i = 1}\\text{Var}(X_i)) = 1/3\\lambda$. \n",
    "\n",
    "Each of the above questions indicates that the $p_i$ used to calculated the variance of approximated normal distribution is not applicable. Lindeberg-Feller CLT would fail to approximate the distribution of mean containing triple occurrence. Use the unconditioned theoretical mean containing probability for each lambda. Examine whether the normal approximation would still hold given that $\\lambda$ is the unbiased estimation.\n",
    "\n",
    "+Terminal digit\n",
    "- How are terminal digits really distributed?\n",
    "    - Figure from notebook\n",
    "+Equal digit\n",
    "- Exchangeability of $\\chi^2$ categories\n",
    "    -example of even vs odd counters\n",
    "\n",
    "We are most concerned that the individual RTS was tested against groups of other investigators. He could be cherry-picked from the ten investigators; furthermore, there could be other fraudulent investigators lingering within the comparison groups, undetected due to lumping of the data. For example, if\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
